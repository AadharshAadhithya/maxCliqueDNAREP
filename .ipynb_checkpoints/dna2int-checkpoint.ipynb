{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "def kmers(k):\n",
    "    '''\n",
    "    Return a list of all possible substrings of\n",
    "    length k using only characters A, C, T, and G\n",
    "    '''\n",
    "    bases = [\"A\", \"C\", \"T\", \"G\"]\n",
    "\n",
    "    last = bases\n",
    "    current = []\n",
    "    for i in range(k-1):\n",
    "        for b in bases:\n",
    "            for l in last:\n",
    "                current.append(l+b)\n",
    "        last = current\n",
    "        current= []\n",
    "    return last\n",
    "class DNA2Neumerical:\n",
    "    def read_data(self, dnadir):\n",
    "        \"\"\"\n",
    "        Reads the data from the directory and returns a list of DNA sequences\n",
    "        and a list of labels.\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        for filename in os.listdir(dnadir):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(dnadir+filename) as f:\n",
    "                    for line in f:\n",
    "                        if line[0] == \">\":\n",
    "                            X.append(line[1:-1])\n",
    "                        else:\n",
    "                            X.append(line[:-1])\n",
    "                        Y.append(filename.split(\"_\")[0])\n",
    "        return X,Y\n",
    "        \n",
    "    def xandy(self, X,Y,M=None):\n",
    "        \"\"\"\n",
    "        X is expected to be an array of strings, containing Neucleotides\n",
    "        Y is expected to be an array of Labels, label from the filename.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y_raw = Y\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.Y  = self.le.fit_transform(self.Y_raw)\n",
    "        if M is not None:\n",
    "            self.M = M\n",
    "        else:\n",
    "            self.M = len(max(self.X, key=len))\n",
    "\n",
    "       \n",
    "    def to_integer(self):\n",
    "        \"\"\"\n",
    "        Returns: \n",
    "        X: ND-Array of size NxM, N-> Number of sequences in X. M defaults to \n",
    "        the length of the longest sequence encountered. Can be specified in constructor\n",
    "        otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            X_ = []\n",
    "            for seq in self.X:\n",
    "                int_rep = [0]*self.M\n",
    "                for i,ch in enumerate(seq):\n",
    "                    if ch== \"A\":\n",
    "                        int_rep[i] = 1\n",
    "                    elif ch==\"C\":\n",
    "                        int_rep[i] = 2\n",
    "                    elif ch==\"G\":\n",
    "                        int_rep[i]= 3\n",
    "                    elif ch==\"T\":\n",
    "                        int_rep[i] = 4\n",
    "                X_.append(int_rep)\n",
    "            return np.asarray(X_) \n",
    "        except IndexError:\n",
    "            print(\"M not sufficiently Large.\")\n",
    "\n",
    "    def train(self, X,Y,feature_name,k):\n",
    "          Xtrain =X\n",
    "          Ytrain = Y\n",
    "\n",
    "          scaler = StandardScaler() #used to scale the data\n",
    "\n",
    "          kfold = RepeatedKFold(  #used to split the data into k folds, k fold is used to train the model \n",
    "            n_splits = k,n_repeats=10)\n",
    "          lda = LinearDiscriminantAnalysis() #used to seperate the classes efficiently\n",
    "\n",
    "          c=1\n",
    "          svm_quad = svm.SVC(kernel='poly',degree=2, C=c,probability=True)\n",
    "\n",
    "          c=1\n",
    "          svm_linear = svm.SVC(kernel='linear',C=c,probability=True)\n",
    "\n",
    "          knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "          lda1 = LinearDiscriminantAnalysis() \n",
    "          subspace_lda  = BaggingClassifier(base_estimator = lda1 , n_estimators = 30,max_features=(1/30),bootstrap=False)\n",
    "\n",
    "          knn1  =  KNeighborsClassifier(n_neighbors = 11)\n",
    "          subspace_knn  = BaggingClassifier(base_estimator = knn1 , n_estimators = 30,max_features=(1/30),bootstrap=False)\n",
    "\n",
    "          lda = lda.fit(Xtrain,Ytrain)\n",
    "          svm_linear  = svm_linear.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          svm_quad = svm_quad.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          knn = knn.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          subspace_lda = subspace_lda.fit(Xtrain,Ytrain)\n",
    "          subspace_knn = subspace_knn.fit(scaler.fit_transform(Xtrain) , Ytrain)\n",
    "\n",
    "          models =  [lda ,svm_linear, svm_quad,knn,subspace_lda,knn,subspace_knn]\n",
    "          model_names = ['Linear Discriminant' , 'Linear SVM' , 'Quadratic SVM' , 'Subspace discriminant' , 'KNN', 'Subspace KNN']\n",
    "          scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score),\n",
    "               'recall' : make_scorer(recall_score), \n",
    "               'f1_score' : make_scorer(f1_score)}\n",
    "          scores={}  \n",
    "          for model,model_name in zip(models,model_names):\n",
    "               score = sklearn.model_selection.cross_validate(model,scaler.fit_transform(Xtrain),Ytrain.ravel(),cv=kfold,scoring=( 'accuracy' ))\n",
    "               print( model_name , ' ' , score )   \n",
    "               scores.update({model_name:score})\n",
    "          return models,scores\n",
    "    def to_proba(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        Normalized ND array of size Nx4. ith row contains the probablity of oobserving the\n",
    "        neuceotide A,C,G,T based on the sequence. \n",
    "        \"\"\"\n",
    "\n",
    "        X_ = []\n",
    "        for seq in self.X:\n",
    "                n = len(seq)\n",
    "                X_.append( [ seq.count(\"A\")/n, seq.count(\"C\")/n, seq.count(\"G\")/n, seq.count(\"T\")/n])\n",
    "        return X_\n",
    "    \n",
    "    def kmer_proba(self,k):\n",
    "        \"\"\"\n",
    "        k: length of kmer\n",
    "        \n",
    "        Returns:\n",
    "        Normalized ND array of size 4^k.\n",
    "        \"\"\"\n",
    "        Kmers = kmers(k)\n",
    "        X_ = []\n",
    "        for seq in self.X:\n",
    "            x_ = []\n",
    "            n = len(seq)\n",
    "            for km in Kmers:\n",
    "                x_.append([seq.count(km)])\n",
    "            X_.append(x_)\n",
    "        return np.array(X_).reshape((-1,4**k))\n",
    "            \n",
    "    def main(self):\n",
    "        X,Y = self.read_data(\"/home/naylak/Documents/test1_maxcliq_rep/\")\n",
    "        self.xandy(X,Y)\n",
    "        k=3\n",
    "        X = self.kmer_proba(k)\n",
    "        self.train(X,self.Y,\"k\",10)\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        #giving only 70% of the data for training using train def and using lda model\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, self.Y, test_size=0.3, random_state=42) \n",
    "        #using lda model\n",
    "        print(\"________________________________________________LDA Model_____________________________________________________________________________\")\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(Xtrain,Ytrain)\n",
    "        Ypred = lda.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))\n",
    "        #using svm model\n",
    "        print(\"________________________________________________SVM_Linear Model_____________________________________________________________________________\")\n",
    "        svm_linear = svm.SVC(kernel='linear',C=1,probability=True)\n",
    "        svm_linear.fit(Xtrain,Ytrain)\n",
    "        Ypred = svm_linear.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))\n",
    "        #using knn model\n",
    "        print(\"________________________________________________KNN Model_____________________________________________________________________________\")\n",
    "        knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "        knn.fit(Xtrain,Ytrain)\n",
    "        Ypred = knn.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))\n",
    "        \n",
    "        #using subspace_lda model\n",
    "        print(\"________________________________________________Subspace_LDA Model_____________________________________________________________________________\")\n",
    "        lda1 = LinearDiscriminantAnalysis()\n",
    "        subspace_lda  = BaggingClassifier(base_estimator = lda1 , n_estimators = 30,max_features=(1/30),bootstrap=False)\n",
    "        subspace_lda.fit(Xtrain,Ytrain)\n",
    "        Ypred = subspace_lda.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))\n",
    "        #using quad_svm\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, self.Y, test_size=0.3, random_state=42)\n",
    "        print(\"________________________________________________SVM_Quadratic Model_____________________________________________________________________________\")\n",
    "        svm_quad = svm.SVC(kernel='poly',degree=2, C=1,probability=True)\n",
    "        svm_quad.fit(Xtrain,Ytrain)\n",
    "        Ypred = svm_quad.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant   {'fit_time': array([0.02476621, 0.05531526, 0.055022  , 0.05206895, 0.05050421,\n",
      "       0.07253766, 0.05395889, 0.05649805, 0.053653  , 0.05160165,\n",
      "       0.05164623, 0.05473375, 0.07341862, 0.05210996, 0.06198907,\n",
      "       0.11860442, 0.06599236, 0.05780125, 0.05282879, 0.07955313,\n",
      "       0.05325532, 0.05631137, 0.05568504, 0.05635285, 0.07968187,\n",
      "       0.05569553, 0.05341506, 0.06021333, 0.05406547, 0.07033062,\n",
      "       0.08790612, 0.06613445, 0.08116102, 0.06690502, 0.08456087,\n",
      "       0.05720282, 0.05561805, 0.07184935, 0.05830336, 0.0576365 ,\n",
      "       0.05612469, 0.05635715, 0.06026673, 0.07551885, 0.09724951,\n",
      "       0.06207061, 0.07608819, 0.05684352, 0.05855322, 0.09273601,\n",
      "       0.0599463 , 0.0539434 , 0.05549741, 0.05796123, 0.07240152,\n",
      "       0.05735779, 0.0535388 , 0.05849528, 0.05506206, 0.08169913,\n",
      "       0.05972695, 0.08218694, 0.05278492, 0.05931497, 0.07358456,\n",
      "       0.05845404, 0.0570538 , 0.09060311, 0.06332088, 0.06262231,\n",
      "       0.05690002, 0.0529089 , 0.05862665, 0.07925582, 0.10175943,\n",
      "       0.06281948, 0.05924129, 0.08515096, 0.05478072, 0.05594826,\n",
      "       0.05459619, 0.06492329, 0.05750799, 0.05663085, 0.09334421,\n",
      "       0.12175107, 0.06421661, 0.05708098, 0.09613228, 0.05748892,\n",
      "       0.08483458, 0.0950501 , 0.06286502, 0.06485963, 0.06978679,\n",
      "       0.05963206, 0.05482745, 0.08085227, 0.05686998, 0.05711985]), 'score_time': array([0.00063491, 0.00073028, 0.00061107, 0.00063705, 0.0006752 ,\n",
      "       0.00071239, 0.00065565, 0.00108719, 0.00139832, 0.00063109,\n",
      "       0.00062418, 0.00077438, 0.00060582, 0.00077534, 0.0006063 ,\n",
      "       0.00067258, 0.0008049 , 0.00160789, 0.00062847, 0.00064754,\n",
      "       0.000772  , 0.00108171, 0.00065589, 0.00092888, 0.00069523,\n",
      "       0.00063324, 0.00068188, 0.00062847, 0.00078726, 0.00073791,\n",
      "       0.0006299 , 0.00064015, 0.00138903, 0.00062418, 0.00060153,\n",
      "       0.00085163, 0.00059605, 0.00118113, 0.00063443, 0.00068831,\n",
      "       0.00060892, 0.0009656 , 0.00068808, 0.00120616, 0.00061607,\n",
      "       0.00131702, 0.00090146, 0.0011611 , 0.00068974, 0.00064445,\n",
      "       0.00062752, 0.0006094 , 0.00075626, 0.00061631, 0.0006392 ,\n",
      "       0.00060058, 0.00080323, 0.00167608, 0.00080919, 0.00095868,\n",
      "       0.000633  , 0.00062346, 0.00064158, 0.0012176 , 0.00096393,\n",
      "       0.0006063 , 0.00070763, 0.00062728, 0.00116467, 0.00100255,\n",
      "       0.0008595 , 0.00109839, 0.00061417, 0.00061488, 0.00066161,\n",
      "       0.0006268 , 0.00089788, 0.00169325, 0.00126481, 0.00102091,\n",
      "       0.00068879, 0.00064898, 0.00080371, 0.00063276, 0.00101042,\n",
      "       0.00071239, 0.00063896, 0.00113225, 0.00112104, 0.00065231,\n",
      "       0.0009985 , 0.0006597 , 0.0006218 , 0.00065947, 0.00064898,\n",
      "       0.0014596 , 0.00071406, 0.00065589, 0.00070548, 0.00062823]), 'test_score': array([0.50609756, 0.57012195, 0.53658537, 0.59327217, 0.57186544,\n",
      "       0.54740061, 0.52599388, 0.56269113, 0.59021407, 0.60856269,\n",
      "       0.5304878 , 0.54573171, 0.55182927, 0.5412844 , 0.55963303,\n",
      "       0.56574924, 0.55963303, 0.59327217, 0.5351682 , 0.59938838,\n",
      "       0.55182927, 0.61890244, 0.60365854, 0.49847095, 0.54740061,\n",
      "       0.55963303, 0.55657492, 0.52905199, 0.59938838, 0.54740061,\n",
      "       0.53658537, 0.52439024, 0.54878049, 0.57492355, 0.57186544,\n",
      "       0.54740061, 0.54740061, 0.55045872, 0.59021407, 0.57492355,\n",
      "       0.58536585, 0.55792683, 0.49390244, 0.55963303, 0.60244648,\n",
      "       0.57798165, 0.55351682, 0.58103976, 0.54434251, 0.55045872,\n",
      "       0.56707317, 0.53353659, 0.53353659, 0.55045872, 0.55963303,\n",
      "       0.59021407, 0.55963303, 0.59633028, 0.56880734, 0.57798165,\n",
      "       0.55792683, 0.51219512, 0.56707317, 0.53211009, 0.59021407,\n",
      "       0.55657492, 0.58103976, 0.56574924, 0.53211009, 0.58715596,\n",
      "       0.54573171, 0.5152439 , 0.51829268, 0.50152905, 0.55351682,\n",
      "       0.59633028, 0.57492355, 0.59938838, 0.54740061, 0.60550459,\n",
      "       0.54573171, 0.50609756, 0.57012195, 0.60550459, 0.57492355,\n",
      "       0.59021407, 0.54740061, 0.58715596, 0.54740061, 0.54740061,\n",
      "       0.53658537, 0.55487805, 0.57317073, 0.5382263 , 0.58409786,\n",
      "       0.59938838, 0.53211009, 0.56574924, 0.56269113, 0.52599388])}\n",
      "Linear SVM   {'fit_time': array([2.14850402, 2.27264047, 2.21665192, 2.27846169, 2.24326015,\n",
      "       2.05956554, 2.04044414, 2.35130191, 2.0455265 , 2.01705694,\n",
      "       2.05355549, 1.95563364, 2.32405925, 2.0049603 , 2.12530589,\n",
      "       1.96588373, 2.00977206, 2.09832668, 2.36026311, 2.15044498,\n",
      "       2.09933281, 2.10371256, 2.13302827, 2.1185813 , 2.24074817,\n",
      "       2.04153919, 2.12047291, 2.21218753, 2.16360784, 2.16214085,\n",
      "       2.09558773, 2.26127458, 2.03467751, 1.91254425, 1.93634081,\n",
      "       2.17623734, 2.18194652, 2.15491223, 2.19922781, 2.08835483,\n",
      "       2.27888489, 2.14085579, 2.17509699, 2.12958574, 2.18300724,\n",
      "       2.15581131, 2.2804296 , 2.12498116, 2.13356853, 2.17414665,\n",
      "       2.06909513, 2.10229397, 2.03637052, 2.16846871, 2.12885594,\n",
      "       2.13513732, 2.18854499, 2.26563525, 2.14114666, 2.03155136,\n",
      "       2.0486331 , 2.06761408, 2.20229793, 2.27553391, 2.13867044,\n",
      "       2.16965723, 2.19774771, 2.12987256, 2.19860816, 2.19099045,\n",
      "       2.27613473, 2.16597152, 2.23141932, 2.08516026, 2.13777471,\n",
      "       2.18937731, 2.21452856, 2.18296146, 2.35356236, 2.2325902 ,\n",
      "       2.14933467, 2.18132949, 2.15520096, 2.19562364, 2.0892241 ,\n",
      "       2.11175108, 2.22293711, 2.19719958, 2.20369506, 2.10314274,\n",
      "       2.15289807, 2.15655994, 2.02152371, 2.11259198, 2.11485624,\n",
      "       2.11421824, 2.13103557, 2.09586787, 2.17600846, 2.10745382]), 'score_time': array([0.02133489, 0.02216601, 0.02258754, 0.02427077, 0.02262473,\n",
      "       0.02000904, 0.02200294, 0.02141023, 0.0205617 , 0.02070832,\n",
      "       0.02079892, 0.02143073, 0.02139282, 0.01995897, 0.02151442,\n",
      "       0.02301431, 0.02168274, 0.02207994, 0.0214355 , 0.02079511,\n",
      "       0.02085996, 0.02152109, 0.02113509, 0.02152443, 0.02116346,\n",
      "       0.02177954, 0.02208972, 0.02268648, 0.02294707, 0.02167988,\n",
      "       0.02182317, 0.02265334, 0.0194695 , 0.01888275, 0.01959014,\n",
      "       0.02177215, 0.02197623, 0.02591801, 0.02234793, 0.02117419,\n",
      "       0.02152133, 0.02075219, 0.02197313, 0.02213335, 0.02328134,\n",
      "       0.02180386, 0.02196288, 0.02955723, 0.02115059, 0.0213871 ,\n",
      "       0.02320075, 0.02369523, 0.02178121, 0.02190351, 0.0210588 ,\n",
      "       0.02110648, 0.02220464, 0.02225327, 0.02103806, 0.02077436,\n",
      "       0.02157807, 0.02321601, 0.02575755, 0.02650881, 0.02079797,\n",
      "       0.02198935, 0.02279353, 0.02160406, 0.02119422, 0.03689289,\n",
      "       0.02284431, 0.02286053, 0.02285957, 0.02429056, 0.02271318,\n",
      "       0.0217793 , 0.02217317, 0.02219582, 0.02128148, 0.02295899,\n",
      "       0.02204823, 0.02096272, 0.02187943, 0.02246404, 0.02112389,\n",
      "       0.02103257, 0.02176547, 0.02690911, 0.02139902, 0.02165127,\n",
      "       0.02163982, 0.02273488, 0.02097487, 0.02058005, 0.02398324,\n",
      "       0.02175546, 0.02083611, 0.02050376, 0.02127433, 0.02116847]), 'test_score': array([0.61280488, 0.68292683, 0.67682927, 0.65749235, 0.63608563,\n",
      "       0.59938838, 0.62385321, 0.66055046, 0.60550459, 0.65137615,\n",
      "       0.61280488, 0.625     , 0.61890244, 0.62385321, 0.62691131,\n",
      "       0.63914373, 0.63302752, 0.68807339, 0.66972477, 0.617737  ,\n",
      "       0.62804878, 0.66463415, 0.64634146, 0.62691131, 0.63608563,\n",
      "       0.59327217, 0.63914373, 0.66666667, 0.65443425, 0.62691131,\n",
      "       0.6554878 , 0.68597561, 0.59756098, 0.66360856, 0.66055046,\n",
      "       0.56880734, 0.62996942, 0.64220183, 0.68195719, 0.66055046,\n",
      "       0.63719512, 0.5945122 , 0.6402439 , 0.65443425, 0.65749235,\n",
      "       0.60244648, 0.66666667, 0.69724771, 0.59021407, 0.6911315 ,\n",
      "       0.63109756, 0.6554878 , 0.60670732, 0.62996942, 0.65137615,\n",
      "       0.64831804, 0.62079511, 0.68807339, 0.63914373, 0.62996942,\n",
      "       0.61585366, 0.58841463, 0.69207317, 0.62385321, 0.6116208 ,\n",
      "       0.63608563, 0.67584098, 0.66055046, 0.65749235, 0.64831804,\n",
      "       0.64939024, 0.65243902, 0.6097561 , 0.63302752, 0.64525994,\n",
      "       0.65443425, 0.63608563, 0.66360856, 0.60856269, 0.65749235,\n",
      "       0.63414634, 0.65243902, 0.67378049, 0.63608563, 0.62691131,\n",
      "       0.64220183, 0.66055046, 0.63302752, 0.68501529, 0.57798165,\n",
      "       0.625     , 0.67378049, 0.61890244, 0.64525994, 0.65749235,\n",
      "       0.6116208 , 0.70030581, 0.63914373, 0.63608563, 0.617737  ])}\n",
      "Quadratic SVM   {'fit_time': array([1.44205809, 1.38562346, 1.31777978, 1.33262348, 1.37396407,\n",
      "       1.36547565, 1.33581853, 1.31225705, 1.34510374, 1.34403849,\n",
      "       1.35995007, 1.36356521, 1.38230634, 1.31987047, 1.30770659,\n",
      "       1.33213472, 1.31797934, 1.33024049, 1.36161351, 1.36085844,\n",
      "       1.34778905, 1.3530798 , 1.30048466, 1.28722405, 1.32685208,\n",
      "       1.38463521, 1.27582121, 1.29835653, 1.28680229, 1.27705574,\n",
      "       1.30186534, 1.24785185, 1.26025414, 1.26509619, 1.25696683,\n",
      "       1.27053714, 1.25909567, 1.28411245, 1.30327201, 1.30109406,\n",
      "       1.29931092, 1.33654404, 1.30975199, 1.28819132, 1.29600358,\n",
      "       1.30461907, 1.28388667, 1.27839923, 1.27594638, 1.32148838,\n",
      "       1.3712759 , 1.3022964 , 1.36419296, 1.35139608, 1.28624678,\n",
      "       1.28632569, 1.33492708, 1.35635448, 1.35888314, 1.32104039,\n",
      "       1.32415438, 1.27560663, 1.28305459, 1.29045105, 1.29644775,\n",
      "       1.28474474, 1.28995538, 1.3447938 , 1.31001663, 1.27560043,\n",
      "       1.27902102, 1.4207015 , 1.2973454 , 1.29034472, 1.32837558,\n",
      "       1.28580165, 1.29325223, 1.27970386, 1.32803631, 1.33208275,\n",
      "       1.25966954, 1.28015232, 1.29629278, 1.33202028, 1.27493477,\n",
      "       1.27226329, 1.26332164, 1.27799082, 1.3134675 , 1.26783466,\n",
      "       1.29669666, 1.32486963, 1.28600335, 1.27945685, 1.28044629,\n",
      "       1.27225518, 1.29407477, 1.31745744, 1.28978491, 1.28519058]), 'score_time': array([0.02982187, 0.03174663, 0.03299904, 0.02934074, 0.033777  ,\n",
      "       0.03001976, 0.0294764 , 0.02827954, 0.0300293 , 0.02947831,\n",
      "       0.04154968, 0.02932906, 0.03110456, 0.02962637, 0.03367615,\n",
      "       0.02871251, 0.03042531, 0.02870798, 0.02816319, 0.02855134,\n",
      "       0.02916908, 0.02882552, 0.03098011, 0.02915764, 0.03290558,\n",
      "       0.02900743, 0.02801251, 0.03002143, 0.02891445, 0.02826786,\n",
      "       0.02854991, 0.02662039, 0.02738547, 0.03993273, 0.02750921,\n",
      "       0.03032804, 0.02890778, 0.02782106, 0.03095341, 0.02854753,\n",
      "       0.03049541, 0.03174615, 0.02905679, 0.02960157, 0.02907228,\n",
      "       0.02916002, 0.02830696, 0.02932739, 0.02766919, 0.03906655,\n",
      "       0.0295403 , 0.02907372, 0.03489137, 0.02801347, 0.03533292,\n",
      "       0.029953  , 0.0463531 , 0.03973961, 0.02892709, 0.02971482,\n",
      "       0.03057551, 0.02837873, 0.02843022, 0.02793026, 0.02821136,\n",
      "       0.02840257, 0.02739978, 0.03407264, 0.03783607, 0.02948689,\n",
      "       0.02895379, 0.0326159 , 0.02876306, 0.03164268, 0.03443146,\n",
      "       0.02922606, 0.02863169, 0.02865314, 0.03049612, 0.03047037,\n",
      "       0.02952409, 0.02980638, 0.02786088, 0.03023624, 0.02841687,\n",
      "       0.03086114, 0.0282371 , 0.02842546, 0.02936363, 0.02867532,\n",
      "       0.04197073, 0.0289197 , 0.02869701, 0.03573012, 0.02874804,\n",
      "       0.02765131, 0.02878451, 0.02921486, 0.03063345, 0.02844095]), 'test_score': array([0.58536585, 0.60365854, 0.63719512, 0.62996942, 0.58715596,\n",
      "       0.6146789 , 0.617737  , 0.6116208 , 0.63914373, 0.63302752,\n",
      "       0.60060976, 0.61890244, 0.64634146, 0.62079511, 0.59938838,\n",
      "       0.57798165, 0.59938838, 0.60244648, 0.6116208 , 0.62996942,\n",
      "       0.61585366, 0.6097561 , 0.61585366, 0.60550459, 0.57186544,\n",
      "       0.62079511, 0.617737  , 0.64525994, 0.6941896 , 0.60244648,\n",
      "       0.59146341, 0.56097561, 0.64329268, 0.63608563, 0.59633028,\n",
      "       0.6116208 , 0.57492355, 0.66360856, 0.63302752, 0.62996942,\n",
      "       0.57621951, 0.59756098, 0.59756098, 0.60856269, 0.617737  ,\n",
      "       0.63608563, 0.64525994, 0.60550459, 0.56574924, 0.66360856,\n",
      "       0.64634146, 0.61890244, 0.61890244, 0.58103976, 0.617737  ,\n",
      "       0.65749235, 0.56880734, 0.64831804, 0.64220183, 0.59938838,\n",
      "       0.63109756, 0.62195122, 0.60670732, 0.59327217, 0.60856269,\n",
      "       0.62996942, 0.64220183, 0.62385321, 0.54434251, 0.63302752,\n",
      "       0.63719512, 0.60670732, 0.61280488, 0.60856269, 0.59633028,\n",
      "       0.55045872, 0.6146789 , 0.63608563, 0.62691131, 0.617737  ,\n",
      "       0.60670732, 0.61890244, 0.6097561 , 0.63608563, 0.57492355,\n",
      "       0.55963303, 0.63302752, 0.60856269, 0.66055046, 0.60244648,\n",
      "       0.64939024, 0.64939024, 0.56097561, 0.6146789 , 0.63302752,\n",
      "       0.65749235, 0.62691131, 0.59938838, 0.62691131, 0.56880734])}\n",
      "Subspace discriminant   {'fit_time': array([0.00042033, 0.00080204, 0.00073576, 0.00067115, 0.00094485,\n",
      "       0.00103259, 0.00085163, 0.00082374, 0.00172567, 0.00084543,\n",
      "       0.0028162 , 0.00268602, 0.00078154, 0.00076747, 0.001261  ,\n",
      "       0.00082827, 0.00221729, 0.00237274, 0.00224972, 0.00270104,\n",
      "       0.00074649, 0.00076914, 0.00111032, 0.00248384, 0.00142717,\n",
      "       0.00082326, 0.00164032, 0.00481606, 0.0011549 , 0.00198054,\n",
      "       0.00263524, 0.00082898, 0.00302625, 0.00197959, 0.0014627 ,\n",
      "       0.00110412, 0.00115156, 0.00146317, 0.00194073, 0.00111151,\n",
      "       0.00111008, 0.00113559, 0.00112152, 0.00154614, 0.00260448,\n",
      "       0.00144434, 0.0011251 , 0.00109577, 0.0011673 , 0.00154257,\n",
      "       0.00197816, 0.00200963, 0.0010705 , 0.00113535, 0.00085878,\n",
      "       0.00216413, 0.00287247, 0.00085306, 0.00122213, 0.00076222,\n",
      "       0.00066876, 0.0007813 , 0.00254822, 0.00303245, 0.00160956,\n",
      "       0.00204158, 0.00262022, 0.00274682, 0.00170636, 0.00289774,\n",
      "       0.0013082 , 0.00190425, 0.00191641, 0.00076461, 0.0007453 ,\n",
      "       0.00075364, 0.00082207, 0.0031271 , 0.00278616, 0.00088716,\n",
      "       0.00217271, 0.00111318, 0.00379515, 0.00081563, 0.00076175,\n",
      "       0.00097036, 0.00108051, 0.00215507, 0.00107598, 0.00078511,\n",
      "       0.00077486, 0.00075293, 0.00263309, 0.00104046, 0.00243616,\n",
      "       0.00130296, 0.00138807, 0.00074768, 0.00074148, 0.00112939]), 'score_time': array([0.010288  , 0.00961304, 0.00937963, 0.05143881, 0.02187204,\n",
      "       0.00948906, 0.01534963, 0.01443338, 0.02144384, 0.01781869,\n",
      "       0.0133121 , 0.04978061, 0.02024603, 0.0167675 , 0.01457167,\n",
      "       0.01664257, 0.03334022, 0.04447746, 0.01953149, 0.03762436,\n",
      "       0.01171446, 0.01051092, 0.01306891, 0.01142454, 0.01428199,\n",
      "       0.01973081, 0.01148963, 0.0152514 , 0.01304317, 0.01176786,\n",
      "       0.01274443, 0.0230329 , 0.01259232, 0.01339364, 0.01428318,\n",
      "       0.01490951, 0.01382041, 0.01578355, 0.01361084, 0.01507783,\n",
      "       0.01506209, 0.01528144, 0.01540256, 0.01687598, 0.01184082,\n",
      "       0.01446009, 0.0133996 , 0.01494503, 0.01471543, 0.01780152,\n",
      "       0.01185751, 0.01385713, 0.01468897, 0.01788855, 0.04381943,\n",
      "       0.02770615, 0.01318049, 0.01417875, 0.03036714, 0.01520634,\n",
      "       0.0134325 , 0.01252747, 0.01479244, 0.02702999, 0.0152452 ,\n",
      "       0.01476622, 0.01291966, 0.01293349, 0.01589561, 0.01072335,\n",
      "       0.01264763, 0.01136804, 0.01272273, 0.01444221, 0.01419544,\n",
      "       0.01354194, 0.01029372, 0.03012872, 0.01956511, 0.02585173,\n",
      "       0.01088023, 0.01681137, 0.02074504, 0.01508808, 0.01625133,\n",
      "       0.02039289, 0.01291394, 0.01133418, 0.01372957, 0.01469445,\n",
      "       0.0142498 , 0.01117682, 0.01005626, 0.01246166, 0.01144886,\n",
      "       0.01495814, 0.01352286, 0.01564264, 0.02161455, 0.01314855]), 'test_score': array([0.4695122 , 0.5945122 , 0.55487805, 0.52905199, 0.57492355,\n",
      "       0.50152905, 0.58103976, 0.52293578, 0.49235474, 0.55045872,\n",
      "       0.51219512, 0.57621951, 0.50304878, 0.48318043, 0.50764526,\n",
      "       0.56269113, 0.56880734, 0.60244648, 0.5351682 , 0.47706422,\n",
      "       0.5945122 , 0.53658537, 0.55182927, 0.50458716, 0.52599388,\n",
      "       0.56269113, 0.51070336, 0.5412844 , 0.5351682 , 0.55045872,\n",
      "       0.54878049, 0.53658537, 0.59756098, 0.51376147, 0.59938838,\n",
      "       0.46788991, 0.55045872, 0.5351682 , 0.50764526, 0.55045872,\n",
      "       0.55182927, 0.55487805, 0.55792683, 0.52599388, 0.53211009,\n",
      "       0.55351682, 0.49847095, 0.52599388, 0.5351682 , 0.55657492,\n",
      "       0.53658537, 0.54573171, 0.52439024, 0.51376147, 0.54740061,\n",
      "       0.51987768, 0.51070336, 0.55657492, 0.5351682 , 0.5382263 ,\n",
      "       0.52439024, 0.56097561, 0.5304878 , 0.55351682, 0.51681957,\n",
      "       0.57492355, 0.5382263 , 0.59021407, 0.51070336, 0.48623853,\n",
      "       0.57317073, 0.50304878, 0.55792683, 0.52293578, 0.56880734,\n",
      "       0.51376147, 0.56880734, 0.51987768, 0.50458716, 0.52905199,\n",
      "       0.53963415, 0.54878049, 0.57317073, 0.55045872, 0.52599388,\n",
      "       0.55351682, 0.47706422, 0.54740061, 0.51376147, 0.51681957,\n",
      "       0.53353659, 0.5       , 0.50914634, 0.50764526, 0.56574924,\n",
      "       0.5412844 , 0.52905199, 0.55657492, 0.55351682, 0.54740061])}\n",
      "KNN   {'fit_time': array([0.08304906, 0.08986139, 0.0865252 , 0.08345556, 0.08043933,\n",
      "       0.07844186, 0.07983994, 0.08011794, 0.10099864, 0.08395553,\n",
      "       0.07901216, 0.07694292, 0.07877517, 0.10061479, 0.0811944 ,\n",
      "       0.0804348 , 0.07864642, 0.07978511, 0.07567787, 0.08237004,\n",
      "       0.08280516, 0.10881448, 0.0885489 , 0.08789587, 0.0993166 ,\n",
      "       0.08248425, 0.0784502 , 0.07817984, 0.07878375, 0.0839653 ,\n",
      "       0.0844028 , 0.08601165, 0.08443069, 0.11025929, 0.0795939 ,\n",
      "       0.08808303, 0.08126068, 0.08129859, 0.07762361, 0.07816386,\n",
      "       0.08130908, 0.0758357 , 0.07652378, 0.08113289, 0.07857323,\n",
      "       0.07551479, 0.11243916, 0.07699037, 0.07009244, 0.07045197,\n",
      "       0.07441807, 0.07611537, 0.07483602, 0.06826711, 0.06987333,\n",
      "       0.07466865, 0.07584929, 0.06960726, 0.08283091, 0.10842752,\n",
      "       0.09161019, 0.07648706, 0.07425356, 0.07645154, 0.08264565,\n",
      "       0.08008552, 0.06823921, 0.07062125, 0.07386398, 0.07526278,\n",
      "       0.07916045, 0.0711956 , 0.07338858, 0.08665156, 0.08197021,\n",
      "       0.07936406, 0.07276177, 0.06945181, 0.07553244, 0.0747087 ,\n",
      "       0.07708335, 0.06977773, 0.07319117, 0.07591081, 0.07454181,\n",
      "       0.07876039, 0.06983852, 0.11440015, 0.0692873 , 0.06895161,\n",
      "       0.0743041 , 0.07647705, 0.06855369, 0.07079935, 0.06982017,\n",
      "       0.08720016, 0.07804465, 0.07320261, 0.07204223, 0.07366347]), 'score_time': array([0.00448799, 0.00481057, 0.00475645, 0.00527024, 0.00441718,\n",
      "       0.00448322, 0.00454712, 0.00563455, 0.00689292, 0.00470853,\n",
      "       0.00502491, 0.00467515, 0.00424457, 0.00428104, 0.00506639,\n",
      "       0.00535917, 0.00508046, 0.00485563, 0.00634527, 0.00452518,\n",
      "       0.00463247, 0.00435543, 0.00609827, 0.01289105, 0.00424409,\n",
      "       0.0050776 , 0.00514722, 0.00498724, 0.00543594, 0.00554633,\n",
      "       0.00523615, 0.00567293, 0.00476027, 0.00451708, 0.00669265,\n",
      "       0.00425029, 0.00414085, 0.00509572, 0.00490427, 0.00531316,\n",
      "       0.00586629, 0.0057838 , 0.00501513, 0.00446534, 0.00448489,\n",
      "       0.00527334, 0.00457478, 0.00478029, 0.00428009, 0.0048182 ,\n",
      "       0.0051496 , 0.00433064, 0.00424933, 0.00564289, 0.00425863,\n",
      "       0.00417638, 0.0046463 , 0.00421214, 0.00594926, 0.00792146,\n",
      "       0.00490761, 0.00446343, 0.00508308, 0.00425792, 0.00433898,\n",
      "       0.00429201, 0.00497913, 0.00421548, 0.00434303, 0.00465822,\n",
      "       0.00646925, 0.00501704, 0.00421333, 0.00777602, 0.00424337,\n",
      "       0.00409055, 0.00657964, 0.00463867, 0.00427485, 0.00411534,\n",
      "       0.00452685, 0.00440359, 0.00501776, 0.00478911, 0.00421762,\n",
      "       0.00472784, 0.0042541 , 0.00462413, 0.00473261, 0.00420284,\n",
      "       0.00411677, 0.00470686, 0.00416112, 0.00475955, 0.00448394,\n",
      "       0.00421   , 0.00477028, 0.00604177, 0.00414109, 0.00497365]), 'test_score': array([0.42987805, 0.35060976, 0.33536585, 0.41590214, 0.3883792 ,\n",
      "       0.41284404, 0.39143731, 0.34862385, 0.34556575, 0.382263  ,\n",
      "       0.3445122 , 0.3902439 , 0.39329268, 0.36697248, 0.37308869,\n",
      "       0.44036697, 0.37920489, 0.43119266, 0.3853211 , 0.3883792 ,\n",
      "       0.38719512, 0.34146341, 0.3597561 , 0.36085627, 0.3853211 ,\n",
      "       0.42813456, 0.37920489, 0.40061162, 0.43119266, 0.36697248,\n",
      "       0.375     , 0.41768293, 0.4054878 , 0.3853211 , 0.36085627,\n",
      "       0.40978593, 0.39449541, 0.40672783, 0.36085627, 0.37003058,\n",
      "       0.37804878, 0.4054878 , 0.41768293, 0.41590214, 0.40366972,\n",
      "       0.35474006, 0.36391437, 0.37308869, 0.33639144, 0.3853211 ,\n",
      "       0.39329268, 0.39329268, 0.36585366, 0.40366972, 0.44648318,\n",
      "       0.37308869, 0.37308869, 0.40061162, 0.40366972, 0.3883792 ,\n",
      "       0.32926829, 0.39634146, 0.42073171, 0.37614679, 0.35168196,\n",
      "       0.44954128, 0.382263  , 0.3883792 , 0.35779817, 0.41284404,\n",
      "       0.38109756, 0.41158537, 0.36585366, 0.36085627, 0.35474006,\n",
      "       0.37614679, 0.41896024, 0.35779817, 0.41590214, 0.42201835,\n",
      "       0.31707317, 0.39634146, 0.40853659, 0.36697248, 0.41284404,\n",
      "       0.33639144, 0.37003058, 0.45259939, 0.35168196, 0.37920489,\n",
      "       0.37195122, 0.38414634, 0.3445122 , 0.44648318, 0.39755352,\n",
      "       0.40978593, 0.41284404, 0.29969419, 0.33639144, 0.43425076])}\n",
      "Subspace KNN   {'fit_time': array([0.00072622, 0.00278187, 0.00087595, 0.00118065, 0.00271487,\n",
      "       0.00077176, 0.00196338, 0.00171542, 0.00365114, 0.00074244,\n",
      "       0.00086904, 0.00154281, 0.0014503 , 0.00116706, 0.00129414,\n",
      "       0.00182939, 0.00067234, 0.00269675, 0.00112939, 0.00238013,\n",
      "       0.00203395, 0.00090504, 0.00082302, 0.00075412, 0.00301647,\n",
      "       0.00111246, 0.00095844, 0.00077629, 0.00117588, 0.00156927,\n",
      "       0.00069189, 0.00089836, 0.00112104, 0.00174379, 0.0007937 ,\n",
      "       0.00080061, 0.00100017, 0.00071454, 0.00136209, 0.00288343,\n",
      "       0.00077295, 0.00204849, 0.00329995, 0.00182128, 0.00314116,\n",
      "       0.00124669, 0.00156474, 0.00070953, 0.00318146, 0.00109768,\n",
      "       0.00194716, 0.00163531, 0.00128055, 0.00162196, 0.00069141,\n",
      "       0.00217962, 0.00267553, 0.00191236, 0.00135732, 0.00331879,\n",
      "       0.00141263, 0.0006876 , 0.00078011, 0.00274253, 0.00117946,\n",
      "       0.00157785, 0.00244141, 0.00190711, 0.00066161, 0.0007658 ,\n",
      "       0.00153208, 0.00204611, 0.00134826, 0.00201392, 0.00099063,\n",
      "       0.00170469, 0.00115108, 0.00308323, 0.0009582 , 0.00165701,\n",
      "       0.00078321, 0.00076389, 0.00075507, 0.00074387, 0.00257134,\n",
      "       0.00084472, 0.00079846, 0.00234103, 0.00280738, 0.00127053,\n",
      "       0.00107884, 0.00081515, 0.00180101, 0.00077796, 0.0007937 ,\n",
      "       0.00260592, 0.00118637, 0.00130677, 0.00187945, 0.00141764]), 'score_time': array([0.01126599, 0.01304531, 0.01352906, 0.00995421, 0.01427674,\n",
      "       0.01330423, 0.02705812, 0.02031446, 0.02597737, 0.01200652,\n",
      "       0.01594996, 0.01755667, 0.01541638, 0.01577902, 0.01294589,\n",
      "       0.00968862, 0.01014948, 0.01036954, 0.01291919, 0.01144886,\n",
      "       0.01702356, 0.01214981, 0.01194453, 0.01008749, 0.0101552 ,\n",
      "       0.01265788, 0.01223803, 0.02031183, 0.01304817, 0.01006699,\n",
      "       0.01078796, 0.01033688, 0.01165771, 0.0124588 , 0.01916146,\n",
      "       0.01473188, 0.01065111, 0.04033184, 0.03528643, 0.01196694,\n",
      "       0.01072359, 0.01300764, 0.01238036, 0.01388907, 0.01626325,\n",
      "       0.01298141, 0.0101254 , 0.010077  , 0.01053572, 0.01226664,\n",
      "       0.01174426, 0.01821423, 0.01314902, 0.00995398, 0.01055479,\n",
      "       0.00991821, 0.01190424, 0.01143336, 0.02032018, 0.00994301,\n",
      "       0.00956392, 0.01378059, 0.0103786 , 0.0101018 , 0.01164627,\n",
      "       0.01808167, 0.01142573, 0.00968623, 0.01455283, 0.0105176 ,\n",
      "       0.00998068, 0.01428676, 0.01845002, 0.01044178, 0.01233292,\n",
      "       0.01468825, 0.02033544, 0.02397394, 0.01590705, 0.01007533,\n",
      "       0.01590824, 0.01556325, 0.01474023, 0.0185957 , 0.01261044,\n",
      "       0.01143479, 0.01183486, 0.01198006, 0.01242971, 0.01411247,\n",
      "       0.01288271, 0.01284575, 0.01116753, 0.01236415, 0.01199007,\n",
      "       0.0123713 , 0.01303506, 0.01617503, 0.01333714, 0.00980139]), 'test_score': array([0.52134146, 0.54878049, 0.55182927, 0.5351682 , 0.51681957,\n",
      "       0.5412844 , 0.51376147, 0.47706422, 0.55657492, 0.56269113,\n",
      "       0.54878049, 0.57621951, 0.51829268, 0.55351682, 0.48929664,\n",
      "       0.58103976, 0.51376147, 0.54434251, 0.51681957, 0.54434251,\n",
      "       0.52743902, 0.47865854, 0.54878049, 0.5382263 , 0.50152905,\n",
      "       0.52905199, 0.54434251, 0.57186544, 0.55657492, 0.55045872,\n",
      "       0.55792683, 0.53353659, 0.54573171, 0.5351682 , 0.56880734,\n",
      "       0.54740061, 0.56880734, 0.48929664, 0.5351682 , 0.47706422,\n",
      "       0.53353659, 0.56707317, 0.51219512, 0.50458716, 0.50152905,\n",
      "       0.51987768, 0.55963303, 0.60856269, 0.54434251, 0.52905199,\n",
      "       0.59756098, 0.53658537, 0.57926829, 0.55045872, 0.56574924,\n",
      "       0.50764526, 0.49541284, 0.50458716, 0.55045872, 0.50458716,\n",
      "       0.54878049, 0.57621951, 0.54878049, 0.52599388, 0.51376147,\n",
      "       0.51987768, 0.54740061, 0.51987768, 0.52599388, 0.50152905,\n",
      "       0.57926829, 0.54878049, 0.50609756, 0.53211009, 0.52293578,\n",
      "       0.52293578, 0.55963303, 0.53211009, 0.51987768, 0.5412844 ,\n",
      "       0.56707317, 0.57317073, 0.53353659, 0.58715596, 0.53211009,\n",
      "       0.5382263 , 0.53211009, 0.51070336, 0.49847095, 0.51681957,\n",
      "       0.55792683, 0.5304878 , 0.49085366, 0.5382263 , 0.5351682 ,\n",
      "       0.50152905, 0.54434251, 0.56269113, 0.56269113, 0.51681957])}\n"
     ]
    }
   ],
   "source": [
    "a = DNA2Neumerical()\n",
    "a.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "class DNA2Neumerical:\n",
    "    def read_data(self, dnadir):\n",
    "        \"\"\"\n",
    "        Reads the data from the directory and returns a list of DNA sequences\n",
    "        and a list of labels.\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        Y = []\n",
    "        for filename in os.listdir(dnadir):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(dnadir+filename) as f:\n",
    "                    for line in f:\n",
    "                        if line[0] == \">\":\n",
    "                            X.append(line[1:-1])\n",
    "                        else:\n",
    "                            X.append(line[:-1])\n",
    "                        Y.append(filename.split(\"_\")[0])\n",
    "        return X,Y\n",
    "        \n",
    "    def xandy(self, X,Y,M=None):\n",
    "        \"\"\"\n",
    "        X is expected to be an array of strings, containing Neucleotides\n",
    "        Y is expected to be an array of Labels, label from the filename.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y_raw = Y\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.Y  = self.le.fit_transform(self.Y_raw)\n",
    "        if M is not None:\n",
    "            self.M = M\n",
    "        else:\n",
    "            self.M = len(max(self.X, key=len))\n",
    "\n",
    "       \n",
    "    def to_integer(self):\n",
    "        \"\"\"\n",
    "        Returns: \n",
    "        X: ND-Array of size NxM, N-> Number of sequences in X. M defaults to \n",
    "        the length of the longest sequence encountered. Can be specified in constructor\n",
    "        otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            X_ = []\n",
    "            for seq in self.X:\n",
    "                int_rep = [0]*self.M\n",
    "                for i,ch in enumerate(seq):\n",
    "                    if ch== \"A\":\n",
    "                        int_rep[i] = 1\n",
    "                    elif ch==\"C\":\n",
    "                        int_rep[i] = 2\n",
    "                    elif ch==\"G\":\n",
    "                        int_rep[i]= 3\n",
    "                    elif ch==\"T\":\n",
    "                        int_rep[i] = 4\n",
    "                X_.append(int_rep)\n",
    "            return np.asarray(X_) \n",
    "        except IndexError:\n",
    "            print(\"M not sufficiently Large.\")\n",
    "\n",
    "    def train(self, X,Y,feature_name,k):\n",
    "          Xtrain =X\n",
    "          Ytrain = Y\n",
    "\n",
    "          scaler = StandardScaler() #used to scale the data\n",
    "\n",
    "          kfold = RepeatedKFold(  #used to split the data into k folds, k fold is used to train the model \n",
    "            n_splits = k,n_repeats=10)\n",
    "          lda = LinearDiscriminantAnalysis() #used to seperate the classes efficiently\n",
    "\n",
    "          c=1\n",
    "          svm_quad = svm.SVC(kernel='poly',degree=2, C=c,probability=True)\n",
    "\n",
    "          c=1\n",
    "          svm_linear = svm.SVC(kernel='linear',C=c,probability=True)\n",
    "\n",
    "          knn = KNeighborsClassifier(n_neighbors = 4)\n",
    "\n",
    "          lda1 = LinearDiscriminantAnalysis() \n",
    "          subspace_lda  = BaggingClassifier(base_estimator = lda1 , n_estimators = 30,max_features=(1/30),bootstrap=False)\n",
    "\n",
    "          knn1  =  KNeighborsClassifier(n_neighbors = 11)\n",
    "          subspace_knn  = BaggingClassifier(base_estimator = knn1 , n_estimators = 30,max_features=(1/30),bootstrap=False)\n",
    "\n",
    "          lda = lda.fit(Xtrain,Ytrain)\n",
    "          svm_linear  = svm_linear.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          svm_quad = svm_quad.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          knn = knn.fit(scaler.fit_transform(Xtrain),Ytrain)\n",
    "          subspace_lda = subspace_lda.fit(Xtrain,Ytrain)\n",
    "          subspace_knn = subspace_knn.fit(scaler.fit_transform(Xtrain) , Ytrain)\n",
    "\n",
    "          models =  [lda ,svm_linear, svm_quad,knn,subspace_lda,knn,subspace_knn]\n",
    "          model_names = ['Linear Discriminant' , 'Linear SVM' , 'Quadratic SVM' , 'Subspace discriminant' , 'KNN', 'Subspace KNN']\n",
    "          scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "               'precision' : make_scorer(precision_score),\n",
    "               'recall' : make_scorer(recall_score), \n",
    "               'f1_score' : make_scorer(f1_score)}\n",
    "          scores={}  \n",
    "          for model,model_name in zip(models,model_names):\n",
    "               score = sklearn.model_selection.cross_validate(model,scaler.fit_transform(Xtrain),Ytrain.ravel(),cv=kfold,scoring=( 'accuracy' ))\n",
    "               print( model_name , ' ' , score )   \n",
    "               scores.update({model_name:score})\n",
    "          return models,scores\n",
    "    def to_proba(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        Normalized ND array of size Nx4. ith row contains the probablity of oobserving the\n",
    "        neuceotide A,C,G,T based on the sequence. \n",
    "        \"\"\"\n",
    "        X_ = []\n",
    "        for seq in self.X:\n",
    "                n = len(seq)\n",
    "                X_.append( [ seq.count(\"A\")/n, seq.count(\"C\")/n, seq.count(\"G\")/n, seq.count(\"T\")/n])\n",
    "        return X_\n",
    "    \n",
    "    def main(self):\n",
    "        X,Y = self.read_data(\"/home/naylak/Documents/test1_maxcliq_rep/\")\n",
    "        self.xandy(X,Y)\n",
    "        X = self.to_integer()\n",
    "        self.train(X,self.Y,\"DNA\",10)\n",
    "        X = self.to_proba()\n",
    "        self.train(X,self.Y,\"DNA\",10)\n",
    "        \n",
    "        #using quad_svm\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, self.Y, test_size=0.3, random_state=42)\n",
    "        print(\"________________________________________________SVM_Quadratic Model_____________________________________________________________________________\")\n",
    "        svm_quad = svm.SVC(kernel='poly',degree=2, C=1,probability=True)\n",
    "        svm_quad.fit(Xtrain,Ytrain)\n",
    "        Ypred = svm_quad.predict(Xtest)\n",
    "        print(classification_report(Ytest, Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
